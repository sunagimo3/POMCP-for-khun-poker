{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsrRPHqRKHh4",
        "outputId": "95c09c44-ea76-4112-b797-61ac4b16a41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "先手の学習済み行動分布 (各カード・状態ごと):\n",
            "\n",
            "Card=Q, History=()\n",
            "  Action Check: N=1142, Estimated Prob=0.698\n",
            "  Action Bet: N=494, Estimated Prob=0.302\n",
            "\n",
            "Card=J, History=()\n",
            "  Action Bet: N=12, Estimated Prob=0.007\n",
            "  Action Check: N=1681, Estimated Prob=0.993\n",
            "\n",
            "Card=K, History=()\n",
            "  Action Check: N=1, Estimated Prob=0.001\n",
            "  Action Bet: N=1670, Estimated Prob=0.999\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRywEyJHDFtc",
        "outputId": "27b21523-a07c-428b-8113-6dd4909618fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "先手の学習済み行動分布 (カード・履歴ごと):\n",
            "\n",
            "Card=J, History=()\n",
            "  Action Raise: N=17, Estimated Prob=0.001\n",
            "  Action Check: N=16648, Estimated Prob=0.999\n",
            "\n",
            "Card=J, History=(np.int64(1), np.int64(1))\n",
            "  Action Check: N=9, Estimated Prob=0.529\n",
            "  Action Raise: N=8, Estimated Prob=0.471\n",
            "\n",
            "Card=K, History=()\n",
            "  Action Raise: N=16659, Estimated Prob=1.000\n",
            "  Action Check: N=2, Estimated Prob=0.000\n",
            "\n",
            "Card=K, History=(np.int64(1), np.int64(1))\n",
            "  Action Check: N=6243, Estimated Prob=0.500\n",
            "  Action Raise: N=6243, Estimated Prob=0.500\n",
            "\n",
            "Card=Q, History=()\n",
            "  Action Raise: N=16382, Estimated Prob=0.982\n",
            "  Action Check: N=292, Estimated Prob=0.018\n",
            "\n",
            "Card=Q, History=(np.int64(1), np.int64(1))\n",
            "  Action Check: N=6147, Estimated Prob=0.500\n",
            "  Action Raise: N=6147, Estimated Prob=0.500\n",
            "\n",
            "Card=Q, History=(np.int64(0), np.int64(1))\n",
            "  Action Check: N=76, Estimated Prob=0.349\n",
            "  Action Raise: N=142, Estimated Prob=0.651\n",
            "\n",
            "Card=J, History=(np.int64(0), np.int64(1))\n",
            "  Action Check: N=16631, Estimated Prob=0.999\n",
            "  Action Raise: N=17, Estimated Prob=0.001\n",
            "\n",
            "Card=K, History=(np.int64(0), np.int64(1))\n",
            "  Action Check: N=2, Estimated Prob=1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# =========================\n",
        "# ゲーム設定\n",
        "# =========================\n",
        "cards = [0,1,2]   # J=0, Q=1, K=2\n",
        "card_names = ['J','Q','K']\n",
        "actions = [0,1]   # Check/Fold=0, Bet/Raise/Call=1\n",
        "action_names = ['Check/Fold','Raise/Call']\n",
        "\n",
        "nash_second_player_after_check = {0:[2/3,1/3], 1:[1.0,0.0], 2:[0.0,1.0]}\n",
        "nash_second_player_after_raise = {0:[1.0,0.0], 1:[2/3,1/3], 2:[0.0,1.0]}\n",
        "\n",
        "class Node:\n",
        "    def __init__(self):\n",
        "        self.N = 0\n",
        "        self.Q = 0\n",
        "        self.children = {}\n",
        "\n",
        "trees = defaultdict(Node)\n",
        "\n",
        "def compute_reward(my_card, opp_card, history):\n",
        "    reward = 0\n",
        "    if len(history)==2:\n",
        "        h0,h1 = history\n",
        "        if h0==0 and h1==0: reward = 1 if my_card>opp_card else -1\n",
        "        elif h0==1 and h1==0: reward = 1\n",
        "        elif h0==1 and h1==1: reward = 2 if my_card>opp_card else -2\n",
        "    elif len(history)==3:\n",
        "        h0,h1,h2 = history\n",
        "        if h0==0 and h1==1: reward = -1 if h2==0 else (2 if my_card>opp_card else -2)\n",
        "    return reward\n",
        "\n",
        "def simulate(my_card, history):\n",
        "    opp_card = np.random.choice([c for c in cards if c != my_card])\n",
        "    state = (my_card, tuple(history))\n",
        "    node = trees[state]\n",
        "\n",
        "    if node.N==0 or any(a not in node.children or node.children[a].N==0 for a in actions):\n",
        "        action = np.random.choice(actions)\n",
        "    else:\n",
        "        action = max(actions, key=lambda a: node.children[a].Q + np.sqrt(np.log(node.N+1)/(node.children[a].N+1)))\n",
        "\n",
        "    history_next = history + [action]\n",
        "\n",
        "    if len(history_next)==1:\n",
        "        p = nash_second_player_after_check[opp_card] if history_next[0]==0 else nash_second_player_after_raise[opp_card]\n",
        "        opp_action = np.random.choice(actions, p=p)\n",
        "        history_next.append(opp_action)\n",
        "\n",
        "    reward_total = None\n",
        "    if len(history_next)==2 and history_next[0]==0 and history_next[1]==1:\n",
        "        next_state = (my_card, tuple(history_next))\n",
        "        next_node = trees[next_state]\n",
        "        if next_node.N==0 or any(a not in next_node.children or next_node.children[a].N==0 for a in actions):\n",
        "            next_action = np.random.choice(actions)\n",
        "        else:\n",
        "            next_action = max(actions, key=lambda a: next_node.children[a].Q + np.sqrt(np.log(next_node.N+1)/(next_node.children[a].N+1)))\n",
        "        history_final = history_next + [next_action]\n",
        "        reward_total = compute_reward(my_card, opp_card, history_final)\n",
        "        if next_action not in next_node.children: next_node.children[next_action]=Node()\n",
        "        child2 = next_node.children[next_action]\n",
        "        child2.N += 1\n",
        "        child2.Q += (reward_total - child2.Q)/child2.N\n",
        "        next_node.N += 1\n",
        "    else:\n",
        "        reward_total = compute_reward(my_card, opp_card, history_next)\n",
        "\n",
        "    if action not in node.children: node.children[action]=Node()\n",
        "    child = node.children[action]\n",
        "    child.N += 1\n",
        "    child.Q += (reward_total - child.Q)/child.N\n",
        "    node.N += 1\n",
        "\n",
        "    return reward_total\n",
        "\n",
        "# =========================\n",
        "# 途中報告付き POMCP\n",
        "# =========================\n",
        "n_simulations = 10000000\n",
        "checkpoints = [100, 1000, 10000, 100000, 1000000,2000000,3000000,4000000,5000000,6000000,7000000,8000000,9000000,10000000]\n",
        "rewards_all = []\n",
        "\n",
        "for i in range(n_simulations):\n",
        "    my_card = np.random.choice(cards)\n",
        "    r = simulate(my_card, [])\n",
        "    rewards_all.append(r)\n",
        "\n",
        "    if (i+1) in checkpoints:\n",
        "        print(f\"\\n--- Simulations = {i+1} ---\")\n",
        "        # 初期状態 Raise 頻度\n",
        "        print(\"初期状態 Raise 頻度 (先手カード別)\")\n",
        "        for c in cards:\n",
        "            state = (c, tuple([]))\n",
        "            node = trees[state]\n",
        "            total = sum(child.N for child in node.children.values())\n",
        "            raise_N = node.children[1].N if 1 in node.children else 0\n",
        "            freq = raise_N/total if total>0 else 0\n",
        "            print(f\"  {card_names[c]}: {freq:.3f}\")\n",
        "\n",
        "        # Check->Raise->Call 頻度\n",
        "        print(\"Check->Raise->Call 頻度 (先手カード別)\")\n",
        "        for c in cards:\n",
        "            state = (c, tuple([0,1]))\n",
        "            node = trees[state]\n",
        "            total = sum(child.N for child in node.children.values())\n",
        "            call_N = node.children[1].N if 1 in node.children else 0\n",
        "            freq = call_N/total if total>0 else 0\n",
        "            print(f\"  {card_names[c]}: {freq:.3f}\")\n",
        "\n",
        "        # 初期状態期待値\n",
        "        expected_value = np.mean(rewards_all)\n",
        "        print(f\"初期状態期待値 (カード配布前): {expected_value:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txf4SyzBI9yr",
        "outputId": "063d1b54-9a6e-4302-a2c5-25f1f5b0af2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Simulations = 100 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.065\n",
            "  Q: 0.032\n",
            "  K: 0.579\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.125\n",
            "  Q: 0.042\n",
            "  K: 0.750\n",
            "初期状態期待値 (カード配布前): -0.150\n",
            "\n",
            "--- Simulations = 1000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.012\n",
            "  Q: 0.003\n",
            "  K: 0.349\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.017\n",
            "  Q: 0.017\n",
            "  K: 0.977\n",
            "初期状態期待値 (カード配布前): -0.100\n",
            "\n",
            "--- Simulations = 10000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.004\n",
            "  Q: 0.001\n",
            "  K: 0.553\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.004\n",
            "  Q: 0.459\n",
            "  K: 0.995\n",
            "初期状態期待値 (カード配布前): -0.075\n",
            "\n",
            "--- Simulations = 100000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.169\n",
            "  Q: 0.000\n",
            "  K: 0.662\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.001\n",
            "  Q: 0.293\n",
            "  K: 0.999\n",
            "初期状態期待値 (カード配布前): -0.058\n",
            "\n",
            "--- Simulations = 1000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.517\n",
            "  Q: 0.001\n",
            "  K: 0.504\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.047\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.055\n",
            "\n",
            "--- Simulations = 2000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.675\n",
            "  Q: 0.001\n",
            "  K: 0.548\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.270\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.055\n",
            "\n",
            "--- Simulations = 3000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.592\n",
            "  Q: 0.000\n",
            "  K: 0.494\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.189\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.056\n",
            "\n",
            "--- Simulations = 4000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.494\n",
            "  Q: 0.000\n",
            "  K: 0.487\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.144\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.056\n",
            "\n",
            "--- Simulations = 5000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.456\n",
            "  Q: 0.000\n",
            "  K: 0.521\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.117\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.056\n",
            "\n",
            "--- Simulations = 6000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.405\n",
            "  Q: 0.000\n",
            "  K: 0.492\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.107\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.056\n",
            "\n",
            "--- Simulations = 7000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.410\n",
            "  Q: 0.000\n",
            "  K: 0.470\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.093\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.056\n",
            "\n",
            "--- Simulations = 8000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.376\n",
            "  Q: 0.000\n",
            "  K: 0.511\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.114\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.056\n",
            "\n",
            "--- Simulations = 9000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.360\n",
            "  Q: 0.000\n",
            "  K: 0.520\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.115\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.056\n",
            "\n",
            "--- Simulations = 10000000 ---\n",
            "初期状態 Raise 頻度 (先手カード別)\n",
            "  J: 0.327\n",
            "  Q: 0.000\n",
            "  K: 0.517\n",
            "Check->Raise->Call 頻度 (先手カード別)\n",
            "  J: 0.000\n",
            "  Q: 0.103\n",
            "  K: 1.000\n",
            "初期状態期待値 (カード配布前): -0.056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZQL8U73xIFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# =========================\n",
        "# 1. ゲーム設定\n",
        "# =========================\n",
        "cards = [0,1,2]   # J=0, Q=1, K=2\n",
        "card_names = ['J','Q','K']\n",
        "actions = [0,1]   # Check/Fold=0, Raise/Call=1\n",
        "action_names = ['Check/Fold','Raise/Call']\n",
        "\n",
        "# =========================\n",
        "# 2. 後手固定Nash方策\n",
        "# =========================\n",
        "# 先手Check直後\n",
        "nash_second_player_after_check = {\n",
        "    0: [2/3, 1/3],  # J: Check 2/3, Raise 1/3\n",
        "    1: [1.0, 0.0],  # Q: Check 1, Raise 0\n",
        "    2: [0.0, 1.0],  # K: Check 0, Raise 1\n",
        "}\n",
        "\n",
        "# 先手Raise直後\n",
        "nash_second_player_after_raise = {\n",
        "    0: [1.0, 0.0],    # J: Fold 1, Call 0\n",
        "    1: [2/3, 1/3],    # Q: Fold 2/3, Call 1/3\n",
        "    2: [0.0, 1.0],    # K: Fold 0, Call 1\n",
        "}\n",
        "\n",
        "# =========================\n",
        "# 3. POMCP用ノード定義\n",
        "# =========================\n",
        "class Node:\n",
        "    def __init__(self):\n",
        "        self.N = 0\n",
        "        self.Q = 0\n",
        "        self.children = {}  # action -> Node\n",
        "\n",
        "trees = defaultdict(Node)\n",
        "\n",
        "# =========================\n",
        "# 4. 報酬計算関数\n",
        "# =========================\n",
        "def compute_reward(my_card, opp_card, history):\n",
        "    reward = 0\n",
        "    if len(history)==2:\n",
        "        h0,h1 = history\n",
        "        if h0==0 and h1==0:\n",
        "            reward = 1 if my_card>opp_card else -1\n",
        "        elif h0==0 and h1==1:\n",
        "            reward = -1\n",
        "        elif h0==1 and h1==0:\n",
        "            reward = 1\n",
        "        elif h0==1 and h1==1:\n",
        "            reward = 2 if my_card>opp_card else -2\n",
        "    elif len(history)==3:\n",
        "        h0,h1,h2 = history\n",
        "        if h0==0 and h1==1:\n",
        "            reward = -1 if h2==0 else (2 if my_card>opp_card else -2)\n",
        "    return reward\n",
        "\n",
        "# =========================\n",
        "# 5. POMCPシミュレーション\n",
        "# =========================\n",
        "def simulate(my_card, history):\n",
        "    # 後手のカード\n",
        "    opp_card = np.random.choice([c for c in cards if c!=my_card])\n",
        "\n",
        "    # 現在ノード\n",
        "    state = (my_card, tuple(history))\n",
        "    node = trees[state]\n",
        "\n",
        "    # 先手アクション選択（UCB or ランダム）\n",
        "    if node.N==0 or any(a not in node.children or node.children[a].N==0 for a in actions):\n",
        "        action = np.random.choice(actions)\n",
        "    else:\n",
        "        action = max(actions, key=lambda a: node.children[a].Q + np.sqrt(np.log(node.N+1)/(node.children[a].N+1)))\n",
        "\n",
        "    # 履歴更新\n",
        "    history_next = history + [action]\n",
        "\n",
        "    # 後手のアクション\n",
        "    if len(history_next)==1:\n",
        "        opp_action = np.random.choice(actions, p=nash_second_player_after_check[opp_card])\n",
        "        history_next.append(opp_action)\n",
        "    elif len(history_next)==2 and history_next[0]==1:\n",
        "        opp_action = np.random.choice(actions, p=nash_second_player_after_raise[opp_card])\n",
        "        history_next.append(opp_action)\n",
        "\n",
        "    # 報酬計算\n",
        "    reward = compute_reward(my_card, opp_card, history_next)\n",
        "\n",
        "    # ノード更新\n",
        "    if action not in node.children:\n",
        "        node.children[action] = Node()\n",
        "    child = node.children[action]\n",
        "    child.N += 1\n",
        "    child.Q += (reward - child.Q)/child.N\n",
        "    node.N += 1\n",
        "\n",
        "    # Check → 後手Raise → 先手アクションの更新\n",
        "    if len(history_next)==2 and history_next[0]==0 and history_next[1]==1:\n",
        "        next_state = (my_card, tuple(history_next))\n",
        "        next_node = trees[next_state]\n",
        "        if next_node.N==0 or any(a not in next_node.children or next_node.children[a].N==0 for a in actions):\n",
        "            next_action = np.random.choice(actions)\n",
        "        else:\n",
        "            next_action = max(actions, key=lambda a: next_node.children[a].Q + np.sqrt(np.log(next_node.N+1)/(next_node.children[a].N+1)))\n",
        "        history_final = history_next + [next_action]\n",
        "        reward2 = compute_reward(my_card, opp_card, history_final)\n",
        "        if next_action not in next_node.children:\n",
        "            next_node.children[next_action] = Node()\n",
        "        child2 = next_node.children[next_action]\n",
        "        child2.N += 1\n",
        "        child2.Q += (reward2 - child2.Q)/child2.N\n",
        "        next_node.N += 1\n",
        "\n",
        "    return reward\n",
        "\n",
        "# =========================\n",
        "# 6. シミュレーション実行\n",
        "# =========================\n",
        "n_simulations = 500000\n",
        "for _ in range(n_simulations):\n",
        "    my_card = np.random.choice(cards)\n",
        "    simulate(my_card, [])\n",
        "\n",
        "# =========================\n",
        "# 7. 学習済み行動分布表示\n",
        "# =========================\n",
        "print(\"先手の学習済み行動分布 (カード・履歴ごと):\")\n",
        "for state, node in trees.items():\n",
        "    my_card, history = state\n",
        "    total_N = sum(child.N for child in node.children.values())\n",
        "    print(f\"\\nCard={card_names[my_card]}, History={history}\")\n",
        "    for a, child in node.children.items():\n",
        "        prob = child.N/total_N if total_N>0 else 0\n",
        "        print(f\"  Action {action_names[a]}: N={child.N}, Estimated Prob={prob:.3f}\")\n",
        "\n",
        "# =========================\n",
        "# 8. 先手期待値表示\n",
        "# =========================\n",
        "print(\"\\n先手の期待値 (カード・履歴ごと):\")\n",
        "for state, node in trees.items():\n",
        "    my_card, history = state\n",
        "    total_N = sum(child.N for child in node.children.values())\n",
        "    print(f\"\\nCard={card_names[my_card]}, History={history}\")\n",
        "    for a, child in node.children.items():\n",
        "        print(f\"  Action {action_names[a]}: Estimated Value={child.Q:.3f}, N={child.N}, Prob={child.N/total_N:.3f}\")\n",
        "\n",
        "    if total_N>0:\n",
        "        expected_value = sum((child.N/total_N)*child.Q for child in node.children.values())\n",
        "        print(f\"  -> Expected Value of this state: {expected_value:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTePiab3P2oj",
        "outputId": "805d6854-77b3-4af1-f68d-5e24c9b2c86f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "先手の学習済み行動分布 (カード・履歴ごと):\n",
            "\n",
            "Card=J, History=()\n",
            "  Action Raise/Call: N=166888, Estimated Prob=0.999\n",
            "  Action Check/Fold: N=88, Estimated Prob=0.001\n",
            "\n",
            "Card=K, History=()\n",
            "  Action Raise/Call: N=166545, Estimated Prob=1.000\n",
            "  Action Check/Fold: N=43, Estimated Prob=0.000\n",
            "\n",
            "Card=Q, History=()\n",
            "  Action Check/Fold: N=148399, Estimated Prob=0.892\n",
            "  Action Raise/Call: N=18037, Estimated Prob=0.108\n",
            "\n",
            "Card=Q, History=(np.int64(0), np.int64(1))\n",
            "  Action Check/Fold: N=89035, Estimated Prob=0.900\n",
            "  Action Raise/Call: N=9849, Estimated Prob=0.100\n",
            "\n",
            "Card=J, History=(0, np.int64(1))\n",
            "  Action Check/Fold: N=41, Estimated Prob=0.953\n",
            "  Action Raise/Call: N=2, Estimated Prob=0.047\n",
            "\n",
            "Card=K, History=(0, np.int64(1))\n",
            "  Action Check/Fold: N=1, Estimated Prob=0.125\n",
            "  Action Raise/Call: N=7, Estimated Prob=0.875\n",
            "\n",
            "先手の期待値 (カード・履歴ごと):\n",
            "\n",
            "Card=J, History=()\n",
            "  Action Raise/Call: Estimated Value=-0.500, N=166888, Prob=0.999\n",
            "  Action Check/Fold: Estimated Value=-1.000, N=88, Prob=0.001\n",
            "  -> Expected Value of this state: -0.500\n",
            "\n",
            "Card=K, History=()\n",
            "  Action Raise/Call: Estimated Value=1.167, N=166545, Prob=1.000\n",
            "  Action Check/Fold: Estimated Value=0.628, N=43, Prob=0.000\n",
            "  -> Expected Value of this state: 1.167\n",
            "\n",
            "Card=Q, History=()\n",
            "  Action Check/Fold: Estimated Value=-0.333, N=148399, Prob=0.892\n",
            "  Action Raise/Call: Estimated Value=-0.350, N=18037, Prob=0.108\n",
            "  -> Expected Value of this state: -0.335\n",
            "\n",
            "Card=Q, History=(np.int64(0), np.int64(1))\n",
            "  Action Check/Fold: Estimated Value=-1.000, N=89035, Prob=0.900\n",
            "  Action Raise/Call: Estimated Value=-1.023, N=9849, Prob=0.100\n",
            "  -> Expected Value of this state: -1.002\n",
            "\n",
            "Card=J, History=(0, np.int64(1))\n",
            "  Action Check/Fold: Estimated Value=-1.000, N=41, Prob=0.953\n",
            "  Action Raise/Call: Estimated Value=-2.000, N=2, Prob=0.047\n",
            "  -> Expected Value of this state: -1.047\n",
            "\n",
            "Card=K, History=(0, np.int64(1))\n",
            "  Action Check/Fold: Estimated Value=-1.000, N=1, Prob=0.125\n",
            "  Action Raise/Call: Estimated Value=2.000, N=7, Prob=0.875\n",
            "  -> Expected Value of this state: 1.625\n"
          ]
        }
      ]
    }
  ]
}
